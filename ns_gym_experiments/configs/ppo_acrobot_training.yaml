# PPO Configs

lr_policy: 0.001
lr_critic: 0.001
max_grad_norm: 0.5
ent_weight: 0.0
clip_val: 0.2

hidden_size: 64


## Training Configs
sample_n_epoch: 10
sample_mb_size: 32

# Training parameters from Config
max_episodes: 10000
batch_size: 2048
minibatch_size: 64
n_epochs: 10
hidden_size: 128 # was 64
max_steps: 1600
gamma: 0.9
lamb: 0.95
device: 'cuda'

save_path: "models/ppo_acrobot_128"


num_workers: 2


## Environment Configs
env_name: "Acrobot-v1"


## Experiment Configs
experiment_name: "ppo_acrobot_eval_2025_01_03"
num_exp: 1000
results_dir: "ns_gym_experiments/results/ppo_acrobot_eval_2025_01_03"
logs_dir: "ns_gym_experiments/logs/ppo_acrobot_eval_2025_01_03"





