{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial \n",
    "\n",
    "This notebook provides a quick overview of how ns_gym is designed and how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install the ns_bench package\n",
    "# %pip install -e  .. --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Non-Stationary Gym Like Environment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NS-Gym in at a high level lets users design non-stationary marchov decision processes by modifiing exposed paramters of some base Gymnasium environment.\n",
    "\n",
    "NS-Gym provides wrappers for the Clasic control suite of Gymnasium  environments and three gridworld environments. At each time step these wrappers will modfify the value of the environment parameter thereby altering the transition function of the MDP. Aditionally, the wrapper can can control the level of notification available to decision making agent when there is a change to the tranition function.  \n",
    "\n",
    "The available wrappers are as follows:\n",
    "\n",
    "- The `NSClassicControlWrapper` is compatable with all environments in the classic control suite of environments.\n",
    "- The `NSCliffWalkingWrapper` augments the CliffWalking environment. \n",
    "- The `NSFrozenLakeWrapper` augments the FrozenLake environment. \n",
    "- The `NSBridgeWrapper` augments the Bridge environment.\n",
    "\n",
    "The table below lists all environments and set of observable parameters that can be tuned by NS-Gym.\n",
    "\n",
    "| Env | What are the tunable parameters (AKA the hidden theta) | \n",
    "| --- | -------------------------------------------------------| \n",
    "| Acrobot|\"dt\",\"LINK_LENGTH_1\",\"LINK_LENGTH_2\",\"LINK_MASS_1\",\"LINK_MASS_2\",\"LINK_COM_POS_1\",\"LINK_COM_POS_2\",\"LINK_MOI\"| \n",
    "| Cartpole|\"gravity\",\"masscart\",\"masspole\",\"force_mag\",\"tau\",\"length\"| \n",
    "| Mountain Car Contin | 'power'| \n",
    "| Mountain Car | 'force','gravity'| \n",
    "| Pendulum |'dt', 'g','l', 'm',| \n",
    "| Frozen Lake |'P' (P is a probablity table that defines a categorical distribution for each state action pair)| \n",
    "| Cliff Walking |'P'| \n",
    "| Bridge | \"P\", \"left_side_prob\",\"right_side_prob\" |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedulers and Parameter Update Function\n",
    "\n",
    "In addition to a wrapper, the two other essential components of the package are schedulers and pupdate functions.\n",
    "\n",
    "- **Schedulers:** Functions (really callables) that define **when** to update the value of an envronement transition funciton. They simple return a boolean flag at time steps where the paramters need to updated.\n",
    "- **Update Function:** Defines **how** to update the value of a parameter or probability distribution. If the scheduler returns true, update the parameter accordingly.\n",
    "\n",
    "\n",
    "Seperating each component allows for greater flexibility and in designing experiments.\n",
    "\n",
    "Availble schedulers are found under `ns_gym/schedulers.py`. Parameter update functions are found under the `ns_gym/update_functions` directory. The sch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notification Levels and custom observation and reward types.\n",
    "\n",
    "A key feature of the NS-Gym library is its ability to manage\n",
    "the interaction between the environment and the decision-\n",
    "making agent. \n",
    "Users can configure notifications the agent receives about\n",
    "changes in the NS-MDP at three distinct levels:\n",
    "1. **Basic Notification:** The agent receives a boolean flag in-\n",
    "dicating a change in an environment parameter.\n",
    "2. **Detailed Notification:** In addition to the boolean flag, the\n",
    "agent is informed of the magnitude of the change.\n",
    "3. **Full Environment Model:** Additionally, if the agent re-\n",
    "quires an environmental model for planning purposes (such\n",
    "as in Monte Carlo tree search), NS-Gym can provide a sta-\n",
    "tionary snapshot of the environment. This snapshot aligns\n",
    "with the basic or detailed notification settings configured by\n",
    "the user. If the user seeks a model without detailed notifi-\n",
    "cation, the planning environment is a stationary snapshot of\n",
    "the base environment. Conversely, if detailed notifications\n",
    "are enabled, the agent receives the most up-to-date version\n",
    "of the environment model (but not any future evolutions)\n",
    "\n",
    "To handle the different levels of notification NS-Gym has custom Obsevation and Reward types. The base Observation type is outlined below.\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Observation:\n",
    "    \"\"\"Observation dataclass type. This is the output of the step function in the environment.\n",
    "\n",
    "    Attributes:\n",
    "        state (Union[np.ndarray,int]): The state of the environment\n",
    "        env_change (Union[dict[str, bool],None]): A dictionary of boolean flags indicating what param of the environment has changed.\n",
    "        delta_change (Union[dict[str,float],float]): The amount of change in the transition function of the environment\n",
    "        relative_time (Union[int,float]): The relative time of the observation since the start of the environment episode.\n",
    "    \"\"\"\n",
    "    state : Union[np.ndarray,int]\n",
    "    env_change: Union[dict[str, bool],None] \n",
    "    delta_change: Union[dict[str,float],float,None]\n",
    "    relative_time: Union[int,float]\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of how to use the package\n",
    "\n",
    "The general blueprint to design a non-stationry gym like environment is as follows\n",
    "\n",
    "1. Create a standard Gymnasium environment. This is the \"base\" environment.\n",
    "2. Define which parameters of the base environment we want to update each time step. Observable paramters are in the table above. \n",
    "3. For each parameter map a scheduler to dictate when to update this parameter and an update function to dictate how the paramter is updated.\n",
    "4. Pass the parameters, the update function, and base environment into wrapper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NS Frozenlake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example creating non-stationary FrozenLake. Suppose we wanted to createa an evironment where for the first 3 time steps the transition probablities are deterministic. For each step after the third the probability of going in the indented direction direcition will decrease by a value of 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Make a standard Gymnasium environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ns_bench.wrappers import NSToyTextWrapper\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"FrozenLake-v1\",is_slippery=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define tunable parameters and update functions.\n",
    "\n",
    "From `ns_gym.schedulers` we can import the `ContinuousScheduler` and from `ns_gym.update_functions` we can import the `DistributionDecrmentUpdate` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ns_gym\n",
    "from ns_gym.schedulers import ContinuousScheduler\n",
    "from ns_gym.update_functions import DistributionDecrmentUpdate\n",
    "\n",
    "scheduler = ContinuousScheduler(start=3) #Update the slipperiness at each timestep starting from timestep 4\n",
    "update_function = DistributionDecrmentUpdate(scheduler=scheduler,k = 0.1) #Decrement the slipperiness by 0.1 at each timestep where the scheduler fires true\n",
    "\n",
    "param_name = \"P\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Map update functions to parameter name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {param_name:update_function}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Pass the parameters, the update function, and base environment into wrapper.\n",
    "\n",
    "We can import all wrappers from `ns_gym.wrappers`. In this case we want thee `NSFrozenLakeWrapper`. There are a few parameters of note that control the notification level of the environment. The `change_notification` controls  the basic notification level. The `delta_change_notification` level controls the detailed notification. If the agent needs a copy of the environment for planning, ns_gym can procide a copy at the appropiate notification level using `env.get_planning_env()`. If `change_notification` is set to true then the agent receives the most up to date (stationary) verision of the MDP for planning. Otherwese `env.get_planning_env()` returns the initial MDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ns_gym.wrappers import NSFrozenLakeWrapper\n",
    "\n",
    "\n",
    "env = NSFrozenLakeWrapper(env,params,change_notification=True, delta_change_notification=True, initial_prob_dist=[1,0,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the env/agent interaction loop\n",
    "\n",
    "ns_gym has some decision making agents included in the package. We can import these agents from `ns_gym.benchmark_algorithms`. For illustrative purposes we can import a standard MCTS agent to act on this NS-FrozenLake environment. The environment/agent interaction loop is effectively the same as Gymnasium but with custom obsevation and reward types.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward: 1.0\n"
     ]
    }
   ],
   "source": [
    "from ns_gym.benchmark_algorithms import MCTS\n",
    "\n",
    "done = False\n",
    "truncated = False\n",
    "obs,_  = env.reset()\n",
    "\n",
    "\n",
    "episode_reward = 0\n",
    "while not done and not truncated:\n",
    "    planning_env = env.get_planning_env()\n",
    "    agent = MCTS(planning_env,obs,d=100,m=100,c=1.44,gamma=0.99)\n",
    "    action,_ = agent.search()\n",
    "    obs, reward, done, truncatd, info = env.step(action)\n",
    "    episode_reward += reward.reward\n",
    "\n",
    "print(f\"Episode reward: {episode_reward}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Scheduler\n",
    "One can easily implement their own custom scheduler. The scheduler just needs to be a callable that takes in the current time and outputs a boolean. It also needs to be a subclass of ns_bench.base.Scheduler. This sample custorm scheduler returns true every three MDP steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Custom Scheduler just needs to be a callable that takes in the current time and outputs a boolean. It also needs to be a subclass of ns_bench.base.Scheduler\n",
    "import ns_gym.base as base\n",
    "\n",
    "class MyCustomSchedulerClass(base.Scheduler):\n",
    "    \"\"\"Custom Scheduler as a class\n",
    "    \"\"\"\n",
    "    def __init__(self,k = 3):\n",
    "        self.k = k\n",
    "    def __call__(self,t:int):\n",
    "        return t%self.k==0\n",
    "    \n",
    "scheduler3 = MyCustomSchedulerClass(k=3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Update Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define a custome update function. We can define a parameter update function as a callable class. The the parameter update function is sa subclass of `ns_gym.base.UpdateFn` if its a scalar parameter update. If we are modifying a probability `ns_gym.base.UpdateDistributionFn`. We initialize the update function with its associated scheduler then all we need to implement it the `update` method. The update funcition will only \"fire\" when the scheduler returns true. If there is no update, the `ns_gym.base.UpdateFn` will return the parameter with no change. \n",
    "\n",
    "All update functions return a three tuple `(param, update_bool, parameter_update_amount)`\n",
    "\n",
    "```\n",
    "    Returns:\n",
    "            Any: The updated parameter\n",
    "            bool: Boolean flag indicating whether the parameter was updated or not\n",
    "            float: The amount of change in the parameter\n",
    "```\n",
    "\n",
    "This custom update fuction devides the current parameter value by 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Type, Union \n",
    "from ns_gym.base import Scheduler\n",
    "\n",
    "class MyCustomUpdateFn(base.UpdateFn):\n",
    "    def __init__(self,scheduler) -> None:\n",
    "        super().__init__(scheduler=scheduler) \n",
    "    def update(self,param,t):\n",
    "        return param//2\n",
    "    \n",
    "updateFn3 = MyCustomUpdateFn(scheduler=scheduler3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90ff191ae0e214e12c60803a2fb116bc4b2c25ad0750721266f196187fcbf9c6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('nsmdp_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
